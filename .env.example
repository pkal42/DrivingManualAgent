# Azure AI Agent Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# REQUIRED: Azure AI Foundry Project Settings
# =============================================================================

# Azure AI Foundry project endpoint
# Format: https://<your-project>.api.azureml.ms
# Find in: Azure AI Foundry portal -> Project -> Overview
AZURE_AI_PROJECT_ENDPOINT=https://your-project.api.azureml.ms

# =============================================================================
# REQUIRED: Azure AI Search Settings
# =============================================================================

# Azure AI Search service endpoint
# Format: https://<your-search-service>.search.windows.net
# Find in: Azure Portal -> AI Search -> Overview
AZURE_SEARCH_ENDPOINT=https://your-search-service.search.windows.net

# =============================================================================
# CONFIGURATION PROFILE SELECTION
# =============================================================================

# Configuration profile to use (base, cost-optimized, performance-optimized)
# Default: base
# - base: Balanced configuration (gpt-4o, text-embedding-3-large, 5 results)
# - cost-optimized: ~70-80% cost reduction (gpt-4o-mini, smaller embeddings, 3 results)
# - performance-optimized: Maximum quality at ~2-3x cost (gpt-4.1, 10 results, LLM judge)
CONFIG_PROFILE=base

# =============================================================================
# OPTIONAL: Model Deployment Overrides
# =============================================================================
# These environment variables override the model deployments specified in the
# configuration profile. Only set these if you need to override the profile defaults.

# Chat model deployment name (must be deployed in your AI Foundry project)
# Default from base profile: gpt-4o
# Default from cost-optimized: gpt-4o-mini
# Default from performance-optimized: gpt-4.1
# CHAT_MODEL_DEPLOYMENT=gpt-4o

# Embedding model deployment name
# Default from base profile: text-embedding-3-large
# Default from cost-optimized: text-embedding-3-small
# EMBEDDING_MODEL_DEPLOYMENT=text-embedding-3-large

# Vision model deployment name (for LLM-as-judge image relevance)
# Default from base profile: gpt-4o
# VISION_MODEL_DEPLOYMENT=gpt-4o

# =============================================================================
# OPTIONAL: Model Parameter Overrides
# =============================================================================

# Model temperature (0.0-1.0, higher = more creative)
# Default: 0.7
# AGENT_TEMPERATURE=0.7

# Maximum tokens in generated response
# Default from base profile: 4000
# Default from performance-optimized: 8000
# AGENT_MAX_TOKENS=4000

# =============================================================================
# OPTIONAL: Search Configuration Overrides
# =============================================================================

# Search index name
# Default: driving-rules-hybrid
AZURE_SEARCH_INDEX=driving-rules-hybrid

# Number of search results to retrieve
# Default from base profile: 5
# Default from cost-optimized: 3
# Default from performance-optimized: 10
# Higher values provide more context but increase cost and latency
# SEARCH_TOP_K=5

# Enable semantic reranking (improves relevance but adds cost)
# Default: true
# ENABLE_SEMANTIC_RERANKING=true

# Enable hybrid search (combines keyword + vector search)
# Default: true
# ENABLE_HYBRID_SEARCH=true

# =============================================================================
# OPTIONAL: Image Handling Overrides
# =============================================================================

# Image relevance threshold (0.0-1.0)
# Default: 0.75
# Higher values = fewer but more relevant images
# Lower values = more images but may include less relevant ones
# IMAGE_RELEVANCE_THRESHOLD=0.75

# Maximum images to include per response
# Default from base profile: 3
# Default from cost-optimized: 2
# Default from performance-optimized: 5
# MAX_IMAGES_PER_RESPONSE=3

# Enable LLM-as-judge for image relevance validation
# Default from base profile: false
# Default from performance-optimized: true
# Uses vision model to validate images (increases cost but improves precision)
# ENABLE_LLM_JUDGE=false

# =============================================================================
# OPTIONAL: Agent Runtime Configuration
# =============================================================================

# Enable streaming responses (tokens arrive progressively)
# Default: true
# ENABLE_STREAMING=true

# =============================================================================
# OPTIONAL: Azure Storage Settings
# =============================================================================

# Azure Storage account name (for image retrieval)
# Required only if fetching images from blob storage
AZURE_STORAGE_ACCOUNT=your-storage-account

# Container name for extracted images
# Default: extracted-images
AZURE_STORAGE_CONTAINER_IMAGES=extracted-images

# Container name for PDF files (used by indexing pipeline)
AZURE_STORAGE_CONTAINER_PDFS=pdfs

# =============================================================================
# OPTIONAL: Observability and Monitoring
# =============================================================================

# Enable OpenTelemetry tracing and metrics
# Default: true
# Set to false to disable telemetry
ENABLE_TELEMETRY=true

# Azure Application Insights connection string
# Required for telemetry export to Azure Monitor
# Find in: Azure Portal -> Application Insights -> Overview
APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=your-key;IngestionEndpoint=...

# Service version for telemetry
APP_VERSION=1.0.0

# Deployment environment (development, staging, production)
ENVIRONMENT=development

# =============================================================================
# OPTIONAL: Authentication
# =============================================================================

# Use managed identity for authentication
# Default: true
# Set to false to use connection strings/API keys (development only)
USE_MANAGED_IDENTITY=true

# Development-only: Azure Search API key (not recommended for production)
# AZURE_SEARCH_API_KEY=your-search-api-key

# Development-only: Azure Storage connection string (not recommended for production)
# AZURE_STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=https;...

# =============================================================================
# OPTIONAL: Indexing Pipeline Settings (for indexer scripts)
# =============================================================================

# Indexer names (if different from defaults)
AZURE_SEARCH_INDEXER_NAME=driving-manual-indexer
AZURE_SEARCH_SKILLSET_NAME=driving-manual-skillset
AZURE_SEARCH_DATASOURCE_NAME=driving-manual-datasource

# Indexer monitoring
INDEXER_POLL_INTERVAL=10
INDEXER_TIMEOUT=1800

# =============================================================================
# Configuration Hierarchy and Override Precedence
# =============================================================================
#
# Configuration values are loaded in the following order (later sources override earlier):
#
# 1. Base Configuration (config/base-config.json)
#    - Always loaded first
#    - Provides sensible defaults for all settings
#
# 2. Profile Configuration (config/{profile}.json)
#    - Loaded based on CONFIG_PROFILE environment variable
#    - Overrides specific values from base configuration
#    - Available profiles: cost-optimized, performance-optimized
#
# 3. Environment Variables (this file)
#    - Highest precedence - override both base and profile settings
#    - Useful for deployment-specific overrides or CI/CD
#
# Example configuration loading:
#   Base (gpt-4o, top_k=5) + cost-optimized (gpt-4o-mini, top_k=3) + ENV (top_k=7)
#   Result: gpt-4o-mini, top_k=7
#
# =============================================================================
# Example Usage Scenarios
# =============================================================================
#
# Development (cost-optimized with quick iteration):
#   CONFIG_PROFILE=cost-optimized
#   ENABLE_STREAMING=true
#
# Production (performance-optimized with monitoring):
#   CONFIG_PROFILE=performance-optimized
#   ENABLE_TELEMETRY=true
#   APPLICATIONINSIGHTS_CONNECTION_STRING=...
#
# Testing (minimal configuration):
#   CONFIG_PROFILE=cost-optimized
#   ENABLE_TELEMETRY=false
#   SEARCH_TOP_K=1
#
# Custom hybrid (base with specific overrides):
#   CONFIG_PROFILE=base
#   CHAT_MODEL_DEPLOYMENT=gpt-4.1
#   SEARCH_TOP_K=8
#
# =============================================================================
# Notes
# =============================================================================
#
# 1. Security Best Practices:
#    - Never commit .env file to source control
#    - Use managed identity in production (USE_MANAGED_IDENTITY=true)
#    - Rotate connection strings and keys regularly
#    - Use Azure Key Vault for secrets in production
#
# 2. Development vs Production:
#    - Development: Can use API keys and connection strings
#    - Production: Must use managed identities and RBAC
#
# 3. Required RBAC Roles (when using managed identity):
#    - Application -> AI Search: "Search Index Data Reader"
#    - Application -> Storage: "Storage Blob Data Reader"
#    - Application -> AI Foundry: "Azure AI Developer"
#
# 4. Configuration Validation:
#    Test your configuration with:
#      python src/agent/config_loader.py
#    Or use the validation script:
#      python scripts/validate_config.py
#
# 5. Profile Selection:
#    Choose the right profile for your use case:
#    - Development/Testing: cost-optimized (saves money during iteration)
#    - Production (budget-conscious): base (balanced cost and quality)
#    - Production (quality-critical): performance-optimized (best results)
#    - Custom: base + environment variable overrides
#
# 6. Getting Started:
#    - Copy this file to .env
#    - Fill in required values (AZURE_AI_PROJECT_ENDPOINT, AZURE_SEARCH_ENDPOINT)
#    - Choose a CONFIG_PROFILE (or leave as 'base')
#    - Optional values have sensible defaults from the profile
#    - Test with: python src/agent/config_loader.py
#    - Run agent: python -m src.agent.app "What does a stop sign mean?"
#
